{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842a2921",
   "metadata": {},
   "source": [
    "# Speech Recognition: Theory, Whisper, and Practical Applications\n",
    "\n",
    "## What is Speech Recognition (SR)?\n",
    "Speech Recognition (SR) is the process of converting spoken language into text. It is a cornerstone technology for voice assistants, transcription services, and many accessibility tools.\n",
    "\n",
    "### Historical Context\n",
    "- **1950s:** Early experiments with speech recognition focused on recognizing digits and phonemes.\n",
    "- **1970s:** The development of Hidden Markov Models (HMMs) revolutionized SR by modeling speech as a probabilistic process.\n",
    "- **2000s:** Neural networks, especially deep learning models, significantly improved SR accuracy.\n",
    "- **2020s:** OpenAI's Whisper and similar transformer-based models have set new benchmarks for multilingual and robust SR.\n",
    "\n",
    "### Applications of SR\n",
    "- **Virtual Assistants** (e.g., Siri, Alexa, Google Assistant)\n",
    "- **Transcription Services** (e.g., Otter.ai, Rev)\n",
    "- **Accessibility Tools** (e.g., dictation software for disabled users)\n",
    "- **Customer Support** (e.g., interactive voice response systems)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bf3f2",
   "metadata": {},
   "source": [
    "## What is Whisper?\n",
    "\n",
    "Whisper is an open-source automatic speech recognition (ASR) model developed by OpenAI. It is designed to handle a wide range of languages and accents, making it one of the most versatile and robust SR systems available.\n",
    "\n",
    "### Why is Whisper Exceptional?\n",
    "- **Multilingual Support:** Whisper supports over 50 languages.\n",
    "- **Robustness:** Handles noisy audio and challenging accents well.\n",
    "- **High Accuracy:** State-of-the-art performance on various transcription tasks.\n",
    "- **Open Source:** Freely available for experimentation and development.\n",
    "\n",
    "### How Does Whisper Work?\n",
    "Whisper is based on a **Transformer architecture**, which is particularly effective for sequence-to-sequence tasks like translating audio into text. The model is pre-trained on a large dataset of diverse audio, making it highly generalizable.\n",
    "\n",
    "### Key Use Cases for Whisper\n",
    "- Transcription of meetings and lectures\n",
    "- Translation of spoken language\n",
    "- Creating subtitles for videos\n",
    "\n",
    "Learn more about Whisper on its [GitHub repository](https://github.com/openai/whisper)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a010f",
   "metadata": {},
   "source": [
    "## Using Whisper via OpenAI API\n",
    "\n",
    "Whisper can be accessed through OpenAI's API for seamless integration into applications. Below is an example of how to transcribe audio using Whisper via the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set the API key and model name\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "MODEL = \"whisper-1\"\n",
    "\n",
    "def transcribe_audio_with_api(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio using the OpenAI Whisper API.\n",
    "    :param audio_path: Path to the audio file (e.g., .mp3, .wav)\n",
    "    :return: Transcription text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(audio_path, \"rb\") as audio_file:\n",
    "            response = client.audio.transcriptions.create(\n",
    "                model=MODEL,\n",
    "                file=audio_file\n",
    "            )\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {e}\"\n",
    "\n",
    "# Example usage\n",
    "audio_file_path = \"example_audio.mp3\"\n",
    "transcription = transcribe_audio_with_api(audio_file_path)\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07752ac9",
   "metadata": {},
   "source": [
    "## Deploying Whisper Locally with Faster-Whisper\n",
    "\n",
    "While the OpenAI API is convenient, deploying Whisper locally can be more cost-effective and secure for large-scale or private applications.\n",
    "\n",
    "### Challenges of Local Deployment\n",
    "- **Hardware Requirements:** Whisper models, especially larger ones, require powerful GPUs for real-time performance.\n",
    "- **Model Size:** Models range from a few hundred megabytes to multiple gigabytes, depending on the configuration.\n",
    "- **Code Optimization:** Efficient coding practices are crucial to handle memory and compute resources effectively.\n",
    "\n",
    "### Why Use Faster-Whisper?\n",
    "Faster-Whisper is an optimized version of Whisper that uses quantization techniques and CUDA acceleration to run more efficiently on local hardware.\n",
    "\n",
    "### Installation\n",
    "Install Faster-Whisper using pip:\n",
    "```bash\n",
    "pip install faster-whisper\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import Whisper\n",
    "\n",
    "# Load the model\n",
    "model = Whisper(\"base\")  # Options: tiny, base, small, medium, large\n",
    "\n",
    "def transcribe_audio_locally(audio_path):\n",
    "    \"\"\"\n",
    "    Transcribes audio using the Faster-Whisper library.\n",
    "    :param audio_path: Path to the audio file\n",
    "    :return: Transcription text\n",
    "    \"\"\"\n",
    "    segments, info = model.transcribe(audio_path)\n",
    "    transcription = \"\\n\".join([segment.text for segment in segments])\n",
    "    return transcription\n",
    "\n",
    "# Example usage\n",
    "audio_file_path = \"example_audio.mp3\"\n",
    "transcription = transcribe_audio_locally(audio_file_path)\n",
    "print(transcription)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2a23b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Speech recognition has evolved significantly over decades, and Whisper represents a leap forward in accuracy and robustness.\n",
    "- Whisper is accessible via the OpenAI API for quick integration or can be deployed locally using Faster-Whisper for efficiency.\n",
    "- Understanding the trade-offs between API usage and local deployment is crucial for building scalable and reliable systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

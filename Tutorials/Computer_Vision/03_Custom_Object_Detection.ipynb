{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhY3XJsQTb2YjnEgkzLTTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IvaroEkel/AI-Spielplatz/blob/main/Tutorials/Computer_Vision/03_Custom_Object_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Object Detection\n",
        "\n",
        "You have used already a pre-trained object detection model, which most likely was trained on a common object database (such as COCO 2017, the most popular one). Think of common objects as things that most likely you can see in everyday life: a human, a cup, a dog, a plane, a car or a tree.\n",
        "\n",
        "Let's say your project needs to detect \"not so common\" objects, then most likely a pre-trained object detection model will give you poor results. At this point you're probably wondering what are \"not so common\" objects and why would the pre-trained models have problems detecting them, so as Jack the Ripper said, let's go by parts:\n",
        "### 1. What are \"not so common\" objects?\n",
        "It's as simple as what it says there, object that are not common to see in everyday life. This might be difficult to understand specially for those who live in their labs all day. Believe me, my friend, not everyone sees lab materials or cell anomalies everyday. I'll try to give you a couple of examples and hopefully that gives you a better understanding:\n",
        "- If you are working in material sciences and you have to detect defects on the surface of materials, these defects can be considered as \"not so common\" objects. For example, trapped bubbles in a film, scratches, pinholes or extrusions.\n",
        "- If you are working in biology or medicine and you need to find anomalies from images of tissues or cells, these can also be considered as \"not so common\" objects.\n",
        "\n",
        "### 2. Why pre-trained models wouldn't work well with \"not so common\" objects?\n",
        "These pre-trained models (I'll just refer to them as models for the rest of this lesson for simplicity) were \"taught\" what is an object. Think of it this way: a baby is learning what are fruits and the baby's parents give him a banana, point at it and say the word \"banana\". This happens every day for several weeks, and one day, the baby looks at the banana and screams \"BANANA!\" (check <a href=\"https://youtu.be/UjWeDMMKWSc?si=PGwM4_Y_04Wd2l3h\">this link</a> for an excited minion screaming that word). The parents are so happy that the baby learned what is a banana, and they cheer up and applaud. The next day, the baby sees an apple and screams \"BANANA!\", but there was no banana on sight. The parents go to the baby and say \"No, no banana. Apple\". Next day, the parents show the baby and apple and the baby screams \"APPLE!\". After that, they put a banana on the table and the baby screams \"BANANA!\". The baby was correct! The parents cheer for the baby and applaud.\n",
        "\n",
        "The parents want to do an experiment, they show the baby a cucumber, but the baby can't say a word, no guess, since the baby was never taught what a cucumber is. The parents now show the baby a tomato, and the baby looks at it confused and exclaims \"Apple?\". The baby has never seen a tomato before, but it kinda has the same color as an apple, so the baby goes ahead and tries that guess, but with a lot of uncertainty.\n",
        "\n",
        "Now it's time to analyze the example: the baby is the object detection model and the parents are us, the people who use the object detection model. The fruits and vegetables are the objects we want to detect, and whatever the baby screams is what the object detection model gives us as a result.  Showing fruits to the baby, pointing at it and saying what fruit it is, is the equivalent of training a model to detect something, in this case a fruit. Cheering up and applauding is the same as giving positive feedback to the model, so it continues detecting things correctly. Telling the baby \"No, this is not a banana. This is an apple\" is like penalizing our model for detecting things incorrectly. Since the baby has never seen a cucumber or a tomato (i.e. the vegetables are considered \"not so common\" objects for the baby) it can do either of two things: not give a detection at all (like looking at the cucumber and not knowing what to say) or give a wrong detection (like saying a tomato is an apple).\n",
        "\n",
        "Hopefully at this point you can understand why models available online will not always be able to detect whatever object you need to be detected. The model was not \"taught\" what these objects are, so you cannot expect much from it. That's when custom training in object detection comes in handy.\n",
        "\n",
        "## What is custom object detection?\n",
        "Even though the baby doesn't know what vegetables look like, we can always teach the baby! The same applies for object detection models: we can teach it how new objects look like and create a custom object detector for your project.\n",
        "\n",
        "The main steps for custom training an object detection model are the following:\n",
        "1. Preparation of the working space and the dataset: install all necessary dependencies and organize a folder with the images we have to teach the model (a.k.a. the dataset).\n",
        "2. Annotation and labelling of the images: just as parents point at a banana and then say what it is, we need to draw bounding boxes around objects we want to detect and give them a label (i.e. a name: dog, cat, tomato, whatever the object is). After this, you also need to separate your images into training and evaluation folders.\n",
        "3. Configuration of the training job: equivalent to deciding how the process of teaching will be like, but more complicated than just pointing at a banana and saying what it is. We need to download a pre-trained model and add more knowledge to it. Take into account that you may need to come back to this step after fine-tuning hyperparameters (i.e. after adjusting the parameters of how the model is learning).\n",
        "4. Training: sit down, cross fingers and hope that your configuration works. Here you will use your training images.\n",
        "5. Evaluate your model: here you will use the evaluation images and test how well your model can detect the new objects. This step also includes looking at the metrics and analyzing if you should change parameters in the training configuration. If you are not satisfied with the performance of your model, you need to repeat the steps 3, 4 and 5 as many times as desired (or until you run out of patience).\n",
        "6. Exporting: once you are happy with your model, you can export it to use it easily as the pre-trained models that you can just download and use."
      ],
      "metadata": {
        "id": "a1mct2D1f8_2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚≠ê If you're still here after the long explanation, time to train!\n",
        "\n",
        "Remember that custom training of a model for object detection can take up some time, so in any case you can continue this project after the workshop is finished, there is a lot of information available online about custom training.\n",
        "\n",
        "The easiest tool for beginners might be [Roboflow](https://roboflow.com/), which has [a full tutorial](https://blog.roboflow.com/how-to-train-yolov8-on-a-custom-dataset/) on how you can use it for labeling and training a model.\n",
        "\n",
        "Based on the very same tutorial, you can see here the [tutorial Google Colab notebook](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb). You can use this notebook as a base for your work since most of the code is already there."
      ],
      "metadata": {
        "id": "SIuMoh9IFgTh"
      }
    }
  ]
}